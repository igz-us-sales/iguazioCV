{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facial Recognition Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nuclio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run set_env.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: start-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cv2 import VideoWriter_fourcc, VideoWriter\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import base64\n",
    "import numpy as np\n",
    "\n",
    "def stream_frame_write(context,frame,shard):\n",
    "    headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"X-v3io-function\": \"PutRecords\",\n",
    "            \"X-v3io-session-key\" : os.getenv(\"V3IO_ACCESS_KEY\")\n",
    "          }\n",
    "    data = base64.b64encode(frame)\n",
    "    payload = {\n",
    "            \"Records\": [\n",
    "                {\n",
    "                    \"Data\":  data.decode('utf-8'),\n",
    "                    \"ShardId\" : shard\n",
    "                    }\n",
    "                ]\n",
    "          }\n",
    "    r = requests.post(os.getenv(\"TAGGED_VIDEO_STREAM_URL\"), headers=headers,json=payload)   \n",
    "    return r.text\n",
    "\n",
    "def handler(context, event):\n",
    "    shardId = event.shard_id\n",
    "    event_data=event.body\n",
    "    \n",
    "    # Load the cascade\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # To capture video from webcam.\n",
    "    img = event_data\n",
    "    img = np.frombuffer(img, dtype=np.uint8)\n",
    "    img = cv2.imdecode(img, flags=1)\n",
    "    if bool(os.getenv('ROTATE_180')):\n",
    "        img = cv2.rotate(img, cv2.ROTATE_180) # For some reason my stream is flipped?\n",
    "    context.logger.info(img.shape)\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(img, 1.1, 4)\n",
    "    \n",
    "    # Draw the rectangle around each face\n",
    "    face_count=0\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_count += 1\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        \n",
    "    context.logger.info(\"Face Count: %s\"% face_count )\n",
    "    if face_count > 0 :\n",
    "        ret, buffer = cv2.imencode('.jpg', img)\n",
    "        try:\n",
    "            r = stream_frame_write(context,buffer.tobytes(),shardId)\n",
    "        except:\n",
    "            context.logger.error(\"Failed to save frame for shard %s\"% shardId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import code_to_function, mount_v3io, mlconf\n",
    "import os\n",
    "\n",
    "fn = code_to_function('deploy-facial-recognition', kind='nuclio', handler=\"handler\", project=os.getenv(\"PROJECT\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.with_http(workers=1).apply(mount_v3io())\n",
    "fn.spec.base_spec['spec']['build']['baseImage'] = f\"docker-registry.{os.getenv('IGZ_NAMESPACE_DOMAIN')}:80/{os.getenv('DOCKER_IMAGE')}\"\n",
    "fn.spec.base_spec['spec']['loggerSinks'] = [{'level': 'info'}]\n",
    "fn.spec.min_replicas = 1\n",
    "fn.spec.max_replicas = 1\n",
    "\n",
    "fn.set_env('V3IO_ACCESS_KEY', os.getenv('V3IO_ACCESS_KEY'))\n",
    "fn.set_env('IGZ_CONTAINER', IGZ_CONTAINER)\n",
    "fn.set_env('ROTATE_180', ROTATE_180)\n",
    "\n",
    "trigger_spec={\n",
    "      'kind': 'v3ioStream',\n",
    "      'url' : \"http://v3io-webapi:8081/%s/%s@processorgrp\"% (os.getenv('IGZ_CONTAINER'),os.getenv('RAW_VIDEO_STREAM')),\n",
    "    \"password\": os.getenv('V3IO_ACCESS_KEY'),  \n",
    "    'attributes': {\"pollingIntervalMs\": 500,\n",
    "        \"seekTo\": \"earliest\",\n",
    "        \"readBatchSize\": 100,\n",
    "        \"partitions\": \"0-100\",               \n",
    "                     \n",
    "      }\n",
    "    }\n",
    "fn.add_trigger('image-proc',trigger_spec)\n",
    "\n",
    "fn.export(\"components/yaml/deploy-facial-recognition.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
